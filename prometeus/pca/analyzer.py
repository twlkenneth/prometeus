from typing import List, Tuple, Optional

import numpy as np
import pandas as pd

from sklearn.decomposition import PCA

from .._base import BaseAnalyzer, CUTOFF_METHOD

__all__ = ['PCAnalyzer']


class PCAnalyzer(BaseAnalyzer):
    def __init__(self, df: pd.DataFrame):
        self.df = df
        self.pca = PCA().fit(df)

    def get_loadings(self, by: CUTOFF_METHOD = "cum_var", threshold: float = 0.8, n_components: Optional[int] = None,
                        is_filter: bool = False) -> pd.DataFrame:
        """
        Get PCA loading dataframe

        :param by:
            Cutoff method using Cummulative Variance Plot or Scree Plot
        :param threshold:
            Percentage of variance explained, default 80%
        :param n_components:
            Number of principal components. If None will autogenerated using PCAnalyzer Library, else overwrite.
        :param is_filter:
            If False will show all PCA loadings heatmap. If True, will only show attributes with cells > 0.55.
        """
        df = self.df
        _components = self._get_components(by, threshold) if n_components is None else n_components
        pca = PCA(n_components=_components)
        pca.fit_transform(df)
        pca_loadings = pca.components_.T * np.sqrt(pca.explained_variance_)
        pca_loading_matrix = pd.DataFrame(pca_loadings, columns=[f'PC{i}' for i in range(1, _components + 1)],
                                          index=df.columns)
        return self._process_loading_matrix(pca_loading_matrix, is_filter)

    def get_clustering(self, by: CUTOFF_METHOD, threshold: float = 0.8, n_components: Optional[int] = None,
                       cluster_size: Optional[int] = None) -> pd.DataFrame:
        """
        Get original DataFrame with cluster labelling

        :param by:
            Cutoff method using Cummulative Variance Plot or Scree Plot
        :param threshold:
            Percentage of variance explained, default 80%
        :param n_components:
            Number of principal components. If None will autogenerated using PCAnalyzer Library determined by threshold,
            else overwrite.
        :param cluster_size:
            Number of cluster size desired. If None will autogenerated using PCAnalyzer Library determined by elbow
            method, else overwrite.
        """
        _components = self._get_components(by, threshold) if n_components is None else n_components
        df = self.df.reset_index(drop=True)
        principalDf = self._get_principal_df(_components)
        clusters_range, inertias = self._get_elbow_info(_components)
        _cluster_size = self._get_cluster_size(inertias) if cluster_size is None else cluster_size
        labels = self._generate_kmean_labels(_cluster_size, principalDf)
        return pd.concat([df, labels], axis=1)

    def _get_elbow_info(self, n_components: int) -> Tuple[range, List[float]]:
        """
        Prior preprocessing to extract information to draw elbow graph

        :param threshold:
            Percentage of variance explained, default 80%
        :param n_components:
            Number of principal components. If None will autogenerated using PCAnalyzer Library determined by threshold,
            else overwrite.
        """
        principalDf = self._get_principal_df(n_components)
        return self._generate_intertias(n_components, principalDf)

    def _get_principal_df(self, n_components: int) -> pd.DataFrame:
        """
        Dimension reduced pandas Dataframe from original dataframe

        :param n_components:
            Number of principal components. If None will autogenerated using PCAnalyzer Library determined by threshold,
            else overwrite.
        """
        pca = PCA(n_components=n_components)
        principalComponents = pca.fit_transform(self.df)
        return pd.DataFrame(data=principalComponents
                            , columns=[f'principal component {i}' for i in range(1, n_components + 1)])

    def _get_components(self, by: CUTOFF_METHOD, threshold: float = 0.8) -> int:
        """
        Determine number of components require after Dimensional Reduction

        :param by:
            Cutoff method using Cummulative Variance Plot or Scree Plot
        :param threshold:
            Percentage of variance explained, default 80%
        """
        if by == 'cum_var':
            if threshold < 0.75:
                print("WARNING: Please be advised to have at least 75% of variance being explained!")
            cum_var = self._get_cum_variance()
            return self._get_cumvariance_crossover(cum_var, threshold)
        eigen_val = self.pca.explained_variance_
        return self._get_eigen_values_crossover(eigen_val, 1)

    def _get_cum_variance(self) -> np.ndarray:
        """ PCA cummulative variance results """
        return np.cumsum(self.pca.explained_variance_ratio_)
